{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Model, Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "\n",
        "# âœ… Load the Azure ML workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# âœ… Fetch the registered model\n",
        "model_name = \"catboost-thrombosis-predictor\"  # Update if needed\n",
        "model = Model(ws, name=model_name)\n",
        "\n",
        "print(f\"âœ… Model '{model_name}' found in workspace '{ws.name}'.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ… Model 'catboost-thrombosis-predictor' found in workspace 'mlops-simple-flow'.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1738416136108
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Define the environment for inference\n",
        "env = Environment(name=\"catboost-env\")\n",
        "env.python.conda_dependencies.add_pip_package(\"catboost\")\n",
        "env.python.conda_dependencies.add_pip_package(\"azureml-defaults\")\n",
        "\n",
        "# âœ… Create the inference configuration\n",
        "inference_config = InferenceConfig(\n",
        "    entry_script=\"score.py\",  # Ensure this script exists in your directory\n",
        "    environment=env\n",
        ")\n",
        "print(\"âœ… Inference environment configured.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ… Inference environment configured.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1738416147149
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()\n",
        "print(\"âœ… Deleted failed deployment. Re-deploying...\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Running\n2025-02-01 13:51:09+00:00 Check and wait for operation (e8fb432d-cc4e-4579-90d1-a53cd4c65bfd) to finish.\n2025-02-01 13:51:11+00:00 Deleting service entity.\nSucceeded\nâœ… Deleted failed deployment. Re-deploying...\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1738417874556
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=\"catboost-endpoint\",\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aci_config\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(f\"âœ… Deployment Successful! Endpoint: {service.scoring_uri}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_3110/1252854105.py:1: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  service = Model.deploy(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2025-02-01 13:51:22+00:00 Creating Container Registry if not exists.\n2025-02-01 13:51:23+00:00 Use the existing image.\n2025-02-01 13:51:23+00:00 Generating deployment configuration.\n2025-02-01 13:51:25+00:00 Submitting deployment to compute.\n2025-02-01 13:51:30+00:00 Checking the status of deployment catboost-endpoint."
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model, InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# Define inference configuration\n",
        "inference_config = InferenceConfig(\n",
        "    entry_script=\"score.py\",  # Uses the fixed script\n",
        "    environment=env\n",
        ")\n",
        "\n",
        "# Define deployment configuration\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "# Deploy model again\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=\"catboost-endpoint\",\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aci_config\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(f\"âœ… Deployment Successful! Endpoint: {service.scoring_uri}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_3110/2837512652.py:14: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  service = Model.deploy(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2025-02-01 13:35:19+00:00 Creating Container Registry if not exists.\n2025-02-01 13:35:19+00:00 Registering the environment.\n2025-02-01 13:35:20+00:00 Use the existing image.\n2025-02-01 13:35:21+00:00 Generating deployment configuration.\n2025-02-01 13:35:23+00:00 Submitting deployment to compute.\n2025-02-01 13:35:29+00:00 Checking the status of deployment catboost-endpoint..\n2025-02-01 13:36:54+00:00 Checking the status of inference endpoint catboost-endpoint.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nâœ… Deployment Successful! Endpoint: http://2688756c-8823-4214-9ac2-1161a7e32fa5.westeurope.azurecontainer.io/score\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1738417035322
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_89497c1a4fc5ff5fc5cc3d077d2f7b60/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_89497c1a4fc5ff5fc5cc3d077d2f7b60/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_89497c1a4fc5ff5fc5cc3d077d2f7b60/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2025-02-01T13:36:46,771212200+00:00 - rsyslog/run \n2025-02-01T13:36:46,852986600+00:00 - gunicorn/run \nbash: /azureml-envs/azureml_89497c1a4fc5ff5fc5cc3d077d2f7b60/lib/libtinfo.so.6: no version information available (required by bash)\n2025-02-01T13:36:46,858665700+00:00 | gunicorn/run | \n2025-02-01T13:36:46,862266900+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:46,864504400+00:00 - nginx/run \n2025-02-01T13:36:46,864823100+00:00 | gunicorn/run | AzureML Container Runtime Information\n2025-02-01T13:36:46,872649100+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:46,878520000+00:00 | gunicorn/run | \n2025-02-01T13:36:46,881810700+00:00 | gunicorn/run | \n2025-02-01T13:36:46,893711000+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20240908.v1\n2025-02-01T13:36:46,899151500+00:00 | gunicorn/run | \n2025-02-01T13:36:46,912221200+00:00 | gunicorn/run | \n2025-02-01T13:36:46,922348300+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_89497c1a4fc5ff5fc5cc3d077d2f7b60/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2025-02-01T13:36:46,928946100+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2025-02-01T13:36:46,931389500+00:00 | gunicorn/run | \n2025-02-01T13:36:50,707124600+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                      *  /azureml-envs/azureml_89497c1a4fc5ff5fc5cc3d077d2f7b60\nbase                     /opt/miniconda\n\n2025-02-01T13:36:52,346366432+00:00 | gunicorn/run | \n2025-02-01T13:36:52,352221230+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\nannotated-types==0.7.0\nargcomplete==3.5.3\nattrs==25.1.0\nazure-common==1.1.28\nazure-core==1.32.0\nazure-graphrbac==0.61.2\nazure-identity==1.19.0\nazure-mgmt-authorization==4.0.0\nazure-mgmt-containerregistry==10.3.0\nazure-mgmt-core==1.5.0\nazure-mgmt-keyvault==10.3.1\nazure-mgmt-network==28.1.0\nazure-mgmt-resource==23.2.0\nazure-mgmt-storage==22.0.0\nazureml-core==1.59.0\nazureml-dataprep==5.1.6\nazureml-dataprep-native==41.0.0\nazureml-dataprep-rslex==2.22.5\nazureml-dataset-runtime==1.59.0\nazureml-defaults==1.59.0\nazureml-inference-server-http==1.3.4\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.2.1\nblinker==1.8.2\ncachetools==5.5.1\ncatboost==1.2.7\ncertifi==2025.1.31\ncffi==1.17.1\ncharset-normalizer==3.4.1\nclick==8.1.8\ncloudpickle==2.2.1\ncontextlib2==21.6.0\ncontourpy==1.1.1\ncryptography==44.0.0\ncycler==0.12.1\ndocker==7.1.0\nFlask==2.3.2\nFlask-Cors==5.0.0\nfonttools==4.55.8\nfusepy==3.0.1\ngoogle-api-core==2.24.1\ngoogle-auth==2.38.0\ngoogleapis-common-protos==1.66.0\ngraphviz==0.20.3\ngunicorn==23.0.0\nhumanfriendly==10.0\nidna==3.10\nimportlib_metadata==8.5.0\nimportlib_resources==6.4.5\ninference-schema==1.8\nisodate==0.7.2\nitsdangerous==2.2.0\njeepney==0.8.0\nJinja2==3.1.5\njmespath==1.0.1\njsonpickle==4.0.1\njsonschema==4.23.0\njsonschema-specifications==2023.12.1\nkiwisolver==1.4.7\nknack==0.12.0\nMarkupSafe==2.1.5\nmatplotlib==3.7.5\nmsal==1.31.1\nmsal-extensions==1.2.0\nmsrest==0.7.1\nmsrestazure==0.6.4.post1\nnarwhals==1.24.1\nndg-httpsclient==0.5.1\nnumpy==1.23.5\noauthlib==3.2.2\nopencensus==0.11.4\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.14\npackaging==24.2\npandas==2.0.3\nparamiko==3.5.0\npathspec==0.12.1\npillow==10.4.0\npkginfo==1.12.0\npkgutil_resolve_name==1.3.10\nplotly==6.0.0\nportalocker==2.10.1\nproto-plus==1.26.0\nprotobuf==5.29.3\npsutil==6.1.1\npyarrow==17.0.0\npyasn1==0.6.1\npyasn1_modules==0.4.1\npycparser==2.22\npydantic==2.9.2\npydantic-settings==2.7.1\npydantic_core==2.23.4\nPygments==2.19.1\nPyJWT==2.9.0\nPyNaCl==1.5.0\npyOpenSSL==24.3.0\npyparsing==3.1.4\nPySocks==1.7.1\npython-dateutil==2.9.0.post0\npython-dotenv==1.0.1\npytz==2025.1\nPyYAML==6.0.2\nreferencing==0.35.1\nrequests==2.32.3\nrequests-oauthlib==2.0.0\nrpds-py==0.20.1\nrsa==4.9\nscipy==1.10.1\nSecretStorage==3.3.3\nsix==1.17.0\ntabulate==0.9.0\ntyping_extensions==4.12.2\ntzdata==2025.1\nurllib3==2.2.3\nWerkzeug==3.0.6\nwrapt==1.16.0\nzipp==3.20.2\n\n2025-02-01T13:36:53,625543218+00:00 | gunicorn/run | \n2025-02-01T13:36:53,631631218+00:00 | gunicorn/run | Entry script directory: /var/azureml-app/.\n2025-02-01T13:36:53,633701318+00:00 | gunicorn/run | \n2025-02-01T13:36:53,637329618+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:53,642027718+00:00 | gunicorn/run | Dynamic Python Package Installation\n2025-02-01T13:36:53,646037818+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:53,651302718+00:00 | gunicorn/run | \n2025-02-01T13:36:53,658074618+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n2025-02-01T13:36:53,661066418+00:00 | gunicorn/run | \n2025-02-01T13:36:53,663817318+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:53,670114118+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2025-02-01T13:36:53,671832318+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:53,673635818+00:00 | gunicorn/run | \n2025-02-01T13:36:54,962659918+00:00 | gunicorn/run | \n2025-02-01T13:36:54,965401818+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:54,970754218+00:00 | gunicorn/run | AzureML Inference Server\n2025-02-01T13:36:54,972896318+00:00 | gunicorn/run | ###############################################\n2025-02-01T13:36:54,978810718+00:00 | gunicorn/run | \n2025-02-01T13:36:54,981383918+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2025-02-01 13:36:55,442 I [77] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_89497c1a4fc5ff5fc5cc3d077d2f7b60/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2025-02-01 13:36:55,573 I [77] gunicorn.error - Starting gunicorn 23.0.0\n2025-02-01 13:36:55,576 I [77] gunicorn.error - Listening at: http://0.0.0.0:31311 (77)\n2025-02-01 13:36:55,577 I [77] gunicorn.error - Using worker: sync\n2025-02-01 13:36:55,590 I [143] gunicorn.error - Booting worker with pid: 143\n\nAzure ML Inferencing HTTP server v1.3.4\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/score.py\nModel Directory: /var/azureml-app/azureml-models/catboost-thrombosis-predictor/1\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv/1.3.4\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n2025-02-01 13:36:56,014 W [143] azmlinfsrv - Found extra keys in the config file that are not supported by the server.\nExtra keys = ['AZUREML_ENTRY_SCRIPT', 'SERVICE_NAME', 'WORKSPACE_NAME', 'SCORING_TIMEOUT_MS', 'AZUREML_MODEL_DIR', 'HOSTNAME']\n2025-02-01 13:36:57,050 I [143] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2025-02-01 13:36:57,059 I [143] azmlinfsrv - Starting up app insights client\n2025-02-01 13:36:58,760 I [143] azmlinfsrv.user_script - Found user script at /var/azureml-app/score.py\n2025-02-01 13:36:58,760 I [143] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n2025-02-01 13:36:58,760 I [143] azmlinfsrv.user_script - Invoking user's init function\n2025-02-01 13:36:58,779 I [143] azmlinfsrv.print - âœ… Model loaded successfully!\n2025-02-01 13:36:58,779 I [143] azmlinfsrv.user_script - Users's init has completed successfully\n2025-02-01 13:36:58,783 I [143] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n2025-02-01 13:36:58,783 I [143] azmlinfsrv - Scoring timeout is set to 60000\n2025-02-01 13:36:58,783 I [143] azmlinfsrv - Worker with pid 143 ready for serving traffic\n2025-02-01 13:36:58,795 I [143] gunicorn.access - 127.0.0.1 - - [01/Feb/2025:13:36:58 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"curl/7.58.0\"\n2025-02-01 13:37:09,481 W [143] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2025-02-01 13:37:09,484 I [143] gunicorn.access - 127.0.0.1 - - [01/Feb/2025:13:37:09 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2025-02-01 13:37:09,494 W [143] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2025-02-01 13:37:09,495 I [143] azmlinfsrv - GET /swagger.json 200 0.978ms 2212\n2025-02-01 13:37:09,496 I [143] gunicorn.access - 127.0.0.1 - - [01/Feb/2025:13:37:09 +0000] \"GET /swagger.json HTTP/1.0\" 200 2212 \"-\" \"Go-http-client/1.1\"\n2025-02-01 13:37:14,895 W [143] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2025-02-01 13:37:14,896 I [143] gunicorn.access - 127.0.0.1 - - [01/Feb/2025:13:37:14 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2025-02-01 13:37:14,904 W [143] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2025-02-01 13:37:14,905 I [143] azmlinfsrv - GET /swagger.json 200 0.892ms 2212\n2025-02-01 13:37:14,907 I [143] gunicorn.access - 127.0.0.1 - - [01/Feb/2025:13:37:14 +0000] \"GET /swagger.json HTTP/1.0\" 200 2212 \"-\" \"Go-http-client/1.1\"\n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1738417050991
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"âœ… Your endpoint URL: {service.scoring_uri}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ… Your endpoint URL: http://2688756c-8823-4214-9ac2-1161a7e32fa5.westeurope.azurecontainer.io/score\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1738417089315
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "ENDPOINT_URL = \"\"  # âœ… Replace with actual endpoint\n",
        "\n",
        "input_data = {\n",
        "    \"data\": [\n",
        "        [1, 50, 0, 1, 1, 2, 0, 110.2, 24.5, 1]  # Adjust as needed\n",
        "    ]\n",
        "}\n",
        "\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "response = requests.post(ENDPOINT_URL, json=input_data, headers=headers)\n",
        "print(response.json())  # âœ… Output should be a prediction\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ðŸ“¡ Response from Model: {'error': \"'data' is numpy array of floating point numerical type, it means no categorical features, but 'cat_features' parameter specifies nonzero number of categorical features\"}\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1738417125992
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Request"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace the endpoint-url with the actual URL from Azure ML\n",
        "endpoint_url = \"https://<your-endpoint-url>/score\"\n",
        "\n",
        "# Sample test data (Replace with actual feature values)\n",
        "test_data = {\n",
        "    \"data\": [\n",
        "        {\"gender\": 1, \"ever_married\": 1, \"work_type\": 2, \"Residence_type\": 1, \"smoking_status\": 2, \n",
        "         \"age\": 50.0, \"avg_glucose_level\": 100.0, \"bmi\": 25.0}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Send request\n",
        "response = requests.post(endpoint_url, json=test_data)\n",
        "\n",
        "# Print the response\n",
        "print(\"Predictions:\", response.json())\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}